{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LC - Alexnet Keras Training Leaf with Data Image Generator.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"IG4wprTk4Fcz","colab_type":"code","outputId":"7c9cdaa3-863b-42c2-edef-e44185f4b0ff","executionInfo":{"status":"ok","timestamp":1560336881782,"user_tz":-420,"elapsed":894,"user":{"displayName":"Hafiizh Eko M","photoUrl":"https://lh6.googleusercontent.com/-DhesHy4VyLg/AAAAAAAAAAI/AAAAAAAACLc/N3HEo6RgjZM/s64/photo.jpg","userId":"11156100478132456384"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7kr5cxDnq6EV","colab_type":"code","colab":{}},"source":["import sys\n","import os\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers\n","from keras.models import Sequential\n","from keras.layers import Dropout, Flatten, Dense, Activation, BatchNormalization\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D\n","from keras import callbacks\n","from keras.callbacks import ModelCheckpoint\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Wv1SxtXq_iG","colab_type":"code","colab":{}},"source":["\n","\"\"\"\n","Parameters\n","\"\"\"\n","epochs = 100\n","img_width, img_height =227,227\n","classes_num = 5\n","batch_size=32\n","arsitektur = 'AlexNet'\n","#lr = 0.0004"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rYtkvMKkQuty","colab_type":"code","outputId":"23d34bf7-be00-471b-ea1d-39245464c525","executionInfo":{"status":"ok","timestamp":1560336882158,"user_tz":-420,"elapsed":1217,"user":{"displayName":"Hafiizh Eko M","photoUrl":"https://lh6.googleusercontent.com/-DhesHy4VyLg/AAAAAAAAAAI/AAAAAAAACLc/N3HEo6RgjZM/s64/photo.jpg","userId":"11156100478132456384"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["DATA_DIR = '/content/gdrive/My Drive/CITS Color'\n","\n","train_datagen = ImageDataGenerator(rescale=1./255,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    validation_split=0.2) # set validation split\n","\n","train_generator = train_datagen.flow_from_directory(\n","    DATA_DIR,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='training') # set as training data\n","\n","validation_generator = train_datagen.flow_from_directory(\n","    DATA_DIR, # same directory as training data\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size,\n","    class_mode='categorical',\n","    subset='validation') # set as validation data\n","\n","label_map = (train_generator.class_indices)\n","print(label_map)\n","\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Found 1079 images belonging to 5 classes.\n","Found 268 images belonging to 5 classes.\n","{'Alang Alang': 0, 'Dracaena': 1, 'Rumput Bambu': 2, 'Rumput Gajah': 3, 'Ruscus': 4}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rtpDPeH2rE9A","colab_type":"code","outputId":"61f6d351-d64f-4338-ee18-d365d73c3bfb","executionInfo":{"status":"ok","timestamp":1560336883926,"user_tz":-420,"elapsed":2969,"user":{"displayName":"Hafiizh Eko M","photoUrl":"https://lh6.googleusercontent.com/-DhesHy4VyLg/AAAAAAAAAAI/AAAAAAAACLc/N3HEo6RgjZM/s64/photo.jpg","userId":"11156100478132456384"}},"colab":{"base_uri":"https://localhost:8080/","height":1433}},"source":["\n","\n","# (3) Create a sequential model\n","model = Sequential()\n","\n","# 1st Convolutional Layer\n","model.add(Convolution2D(filters=96, input_shape=(img_width,img_height,3), kernel_size=(11,11),\\\n"," strides=(4,4), padding='valid'))\n","model.add(Activation('relu'))\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation before passing it to the next layer\n","model.add(BatchNormalization())\n","\n","# 2nd Convolutional Layer\n","model.add(Convolution2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 3rd Convolutional Layer\n","model.add(Convolution2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 4th Convolutional Layer\n","model.add(Convolution2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 5th Convolutional Layer\n","model.add(Convolution2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n","model.add(Activation('relu'))\n","# Pooling\n","model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# Passing it to a dense layer\n","model.add(Flatten())\n","# 1st Dense Layer\n","model.add(Dense(4096, input_shape=(img_width*img_height*3,)))\n","model.add(Activation('relu'))\n","# Add Dropout to prevent overfitting\n","model.add(Dropout(0.5))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 2nd Dense Layer\n","model.add(Dense(4096))\n","model.add(Activation('relu'))\n","# Add Dropout\n","model.add(Dropout(0.5))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# 3rd Dense Layer\n","model.add(Dense(1000))\n","model.add(Activation('relu'))\n","# Add Dropout\n","model.add(Dropout(0.4))\n","# Batch Normalisation\n","model.add(BatchNormalization())\n","\n","# Output Layer\n","model.add(Dense(classes_num))\n","model.add(Activation('softmax'))\n","\n","model.summary()\n","\n","\n","architecure_dir = os.path.join('/content/gdrive/My Drive/Colab Notebooks/LeafClassification/',arsitektur)\n","if not os.path.exists(architecure_dir):\n","  os.mkdir(architecure_dir)\n","# Save the model architecture\n","with open(os.path.join(architecure_dir,'architecture.json'), 'w') as f:\n","    f.write(model.to_json())\n","\n"],"execution_count":25,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_16 (Conv2D)           (None, 55, 55, 96)        34944     \n","_________________________________________________________________\n","activation_14 (Activation)   (None, 55, 55, 96)        0         \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 27, 27, 96)        0         \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 27, 27, 96)        384       \n","_________________________________________________________________\n","conv2d_17 (Conv2D)           (None, 23, 23, 256)       614656    \n","_________________________________________________________________\n","activation_15 (Activation)   (None, 23, 23, 256)       0         \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 11, 11, 256)       0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 11, 11, 256)       1024      \n","_________________________________________________________________\n","conv2d_18 (Conv2D)           (None, 9, 9, 384)         885120    \n","_________________________________________________________________\n","activation_16 (Activation)   (None, 9, 9, 384)         0         \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 9, 9, 384)         1536      \n","_________________________________________________________________\n","conv2d_19 (Conv2D)           (None, 7, 7, 384)         1327488   \n","_________________________________________________________________\n","activation_17 (Activation)   (None, 7, 7, 384)         0         \n","_________________________________________________________________\n","batch_normalization_16 (Batc (None, 7, 7, 384)         1536      \n","_________________________________________________________________\n","conv2d_20 (Conv2D)           (None, 5, 5, 256)         884992    \n","_________________________________________________________________\n","activation_18 (Activation)   (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","max_pooling2d_10 (MaxPooling (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","batch_normalization_17 (Batc (None, 2, 2, 256)         1024      \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 4096)              4198400   \n","_________________________________________________________________\n","activation_19 (Activation)   (None, 4096)              0         \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","batch_normalization_18 (Batc (None, 4096)              16384     \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","activation_20 (Activation)   (None, 4096)              0         \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","batch_normalization_19 (Batc (None, 4096)              16384     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1000)              4097000   \n","_________________________________________________________________\n","activation_21 (Activation)   (None, 1000)              0         \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 1000)              0         \n","_________________________________________________________________\n","batch_normalization_20 (Batc (None, 1000)              4000      \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 5)                 5005      \n","_________________________________________________________________\n","activation_22 (Activation)   (None, 5)                 0         \n","=================================================================\n","Total params: 28,871,189\n","Trainable params: 28,850,053\n","Non-trainable params: 21,136\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"i0u7akWJHtMp","colab_type":"code","colab":{}},"source":["from keras.models import model_from_json\n","with open(os.path.join(architecure_dir,'architecture.json'), 'r') as f:\n","    model = model_from_json(f.read())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"L1jXscM3_N7A","colab_type":"code","colab":{}},"source":["# (4) Compile\n","model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-V-D349GqzBH","colab_type":"code","outputId":"7c7a2de0-afa5-4bd6-999d-977e1e3621f9","executionInfo":{"status":"ok","timestamp":1560338528426,"user_tz":-420,"elapsed":1647424,"user":{"displayName":"Hafiizh Eko M","photoUrl":"https://lh6.googleusercontent.com/-DhesHy4VyLg/AAAAAAAAAAI/AAAAAAAACLc/N3HEo6RgjZM/s64/photo.jpg","userId":"11156100478132456384"}},"colab":{"base_uri":"https://localhost:8080/","height":3765}},"source":["\"\"\"\n","Tensorboard log\n","\"\"\"\n","\n","log_dir = os.path.join(architecure_dir, 'tf-log')\n","tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0, write_graph=True, write_images=True)\n","cbks = [tb_cb]\n","\n","\"\"\"model.fit_generator(\n","    train_generator,\n","    samples_per_epoch=samples_per_epoch,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    callbacks=cbks,\n","    validation_steps=validation_steps)\"\"\"\n","\n","model.fit_generator(\n","    train_generator,\n","    steps_per_epoch = train_generator.samples // batch_size,\n","    validation_data = validation_generator, \n","    validation_steps = validation_generator.samples // batch_size,\n","    callbacks=cbks,\n","    epochs = epochs,\n","    shuffle = True)\n","\n","#model.fit_generator(datagen.flow(x_train, y_train, batch_size=32), steps_per_epoch=len(x_train) / 32, epochs=epochs)\n","\n","target_dir =os.path.join(architecure_dir, 'models')\n","if not os.path.exists(target_dir):\n","  os.mkdir(target_dir)\n","  \n","model.save(os.path.join(target_dir, 'model.h5'))\n","model.save_weights(os.path.join(target_dir, 'weights.h5'))"],"execution_count":28,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/100\n","33/33 [==============================] - 302s 9s/step - loss: 1.1286 - acc: 0.6638 - val_loss: 11.3959 - val_acc: 0.2812\n","Epoch 2/100\n","33/33 [==============================] - 18s 540ms/step - loss: 0.6573 - acc: 0.7896 - val_loss: 1.1379 - val_acc: 0.7034\n","Epoch 3/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.4436 - acc: 0.8373 - val_loss: 1.4727 - val_acc: 0.6059\n","Epoch 4/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.4658 - acc: 0.8408 - val_loss: 1.3551 - val_acc: 0.5720\n","Epoch 5/100\n","33/33 [==============================] - 13s 398ms/step - loss: 0.4297 - acc: 0.8372 - val_loss: 0.2154 - val_acc: 0.9280\n","Epoch 6/100\n","33/33 [==============================] - 13s 406ms/step - loss: 0.4146 - acc: 0.8491 - val_loss: 0.6999 - val_acc: 0.7458\n","Epoch 7/100\n","33/33 [==============================] - 13s 404ms/step - loss: 0.3461 - acc: 0.8729 - val_loss: 0.4699 - val_acc: 0.8517\n","Epoch 8/100\n","33/33 [==============================] - 13s 397ms/step - loss: 0.3952 - acc: 0.8625 - val_loss: 0.1577 - val_acc: 0.9237\n","Epoch 9/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.3568 - acc: 0.8742 - val_loss: 0.3771 - val_acc: 0.8602\n","Epoch 10/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.3265 - acc: 0.8745 - val_loss: 0.2366 - val_acc: 0.9258\n","Epoch 11/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.2831 - acc: 0.8915 - val_loss: 2.2803 - val_acc: 0.6398\n","Epoch 12/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.3566 - acc: 0.8660 - val_loss: 0.3966 - val_acc: 0.8475\n","Epoch 13/100\n","33/33 [==============================] - 14s 410ms/step - loss: 0.3056 - acc: 0.8869 - val_loss: 0.4986 - val_acc: 0.8390\n","Epoch 14/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.2813 - acc: 0.8831 - val_loss: 0.1148 - val_acc: 0.9746\n","Epoch 15/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.2898 - acc: 0.8957 - val_loss: 0.7665 - val_acc: 0.7924\n","Epoch 16/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.3412 - acc: 0.8786 - val_loss: 0.1501 - val_acc: 0.9407\n","Epoch 17/100\n","33/33 [==============================] - 13s 405ms/step - loss: 0.2602 - acc: 0.8917 - val_loss: 0.6402 - val_acc: 0.7754\n","Epoch 18/100\n","33/33 [==============================] - 13s 405ms/step - loss: 0.2310 - acc: 0.9095 - val_loss: 1.6046 - val_acc: 0.7669\n","Epoch 19/100\n","33/33 [==============================] - 13s 408ms/step - loss: 0.3077 - acc: 0.8932 - val_loss: 0.6480 - val_acc: 0.7812\n","Epoch 20/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.2950 - acc: 0.8976 - val_loss: 0.7926 - val_acc: 0.7712\n","Epoch 21/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.2623 - acc: 0.9005 - val_loss: 1.3177 - val_acc: 0.6398\n","Epoch 22/100\n","33/33 [==============================] - 13s 409ms/step - loss: 0.2886 - acc: 0.8913 - val_loss: 0.3350 - val_acc: 0.8517\n","Epoch 23/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.2438 - acc: 0.9197 - val_loss: 0.5002 - val_acc: 0.8136\n","Epoch 24/100\n","33/33 [==============================] - 13s 405ms/step - loss: 0.2560 - acc: 0.8950 - val_loss: 0.4167 - val_acc: 0.8432\n","Epoch 25/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.2802 - acc: 0.9040 - val_loss: 0.1666 - val_acc: 0.9407\n","Epoch 26/100\n","33/33 [==============================] - 14s 416ms/step - loss: 0.2584 - acc: 0.9047 - val_loss: 0.8194 - val_acc: 0.7500\n","Epoch 27/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.2624 - acc: 0.9047 - val_loss: 0.4054 - val_acc: 0.8305\n","Epoch 28/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.2903 - acc: 0.8984 - val_loss: 0.2835 - val_acc: 0.8906\n","Epoch 29/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.2314 - acc: 0.9140 - val_loss: 0.1615 - val_acc: 0.9449\n","Epoch 30/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.2579 - acc: 0.9163 - val_loss: 0.5232 - val_acc: 0.8390\n","Epoch 31/100\n","33/33 [==============================] - 14s 411ms/step - loss: 0.2868 - acc: 0.9002 - val_loss: 0.5234 - val_acc: 0.8093\n","Epoch 32/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1962 - acc: 0.9292 - val_loss: 0.2086 - val_acc: 0.9280\n","Epoch 33/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.2060 - acc: 0.9226 - val_loss: 0.1468 - val_acc: 0.9449\n","Epoch 34/100\n","33/33 [==============================] - 13s 397ms/step - loss: 0.1906 - acc: 0.9273 - val_loss: 0.1053 - val_acc: 0.9534\n","Epoch 35/100\n","33/33 [==============================] - 13s 406ms/step - loss: 0.2639 - acc: 0.8977 - val_loss: 0.1492 - val_acc: 0.9322\n","Epoch 36/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1828 - acc: 0.9362 - val_loss: 0.6120 - val_acc: 0.8051\n","Epoch 37/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.2965 - acc: 0.8915 - val_loss: 0.7168 - val_acc: 0.7812\n","Epoch 38/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.2003 - acc: 0.9201 - val_loss: 0.1079 - val_acc: 0.9661\n","Epoch 39/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.1956 - acc: 0.9305 - val_loss: 0.3372 - val_acc: 0.8729\n","Epoch 40/100\n","33/33 [==============================] - 13s 406ms/step - loss: 0.1776 - acc: 0.9295 - val_loss: 0.3849 - val_acc: 0.8856\n","Epoch 41/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.2156 - acc: 0.9233 - val_loss: 0.3502 - val_acc: 0.8941\n","Epoch 42/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.2257 - acc: 0.9178 - val_loss: 0.1939 - val_acc: 0.9407\n","Epoch 43/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.2090 - acc: 0.9235 - val_loss: 0.2475 - val_acc: 0.9237\n","Epoch 44/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1776 - acc: 0.9328 - val_loss: 0.1550 - val_acc: 0.9407\n","Epoch 45/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.1789 - acc: 0.9383 - val_loss: 0.4103 - val_acc: 0.8941\n","Epoch 46/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.1864 - acc: 0.9368 - val_loss: 0.5261 - val_acc: 0.8398\n","Epoch 47/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.2147 - acc: 0.9180 - val_loss: 0.1799 - val_acc: 0.9492\n","Epoch 48/100\n","33/33 [==============================] - 13s 404ms/step - loss: 0.2024 - acc: 0.9234 - val_loss: 0.0949 - val_acc: 0.9661\n","Epoch 49/100\n","33/33 [==============================] - 14s 421ms/step - loss: 0.1763 - acc: 0.9352 - val_loss: 0.2371 - val_acc: 0.9237\n","Epoch 50/100\n","33/33 [==============================] - 13s 405ms/step - loss: 0.2554 - acc: 0.9137 - val_loss: 0.5763 - val_acc: 0.8136\n","Epoch 51/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.2321 - acc: 0.9218 - val_loss: 1.1735 - val_acc: 0.6780\n","Epoch 52/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.2146 - acc: 0.9109 - val_loss: 0.1984 - val_acc: 0.9025\n","Epoch 53/100\n","33/33 [==============================] - 13s 398ms/step - loss: 0.1687 - acc: 0.9370 - val_loss: 0.9700 - val_acc: 0.7500\n","Epoch 54/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.2578 - acc: 0.9097 - val_loss: 1.1297 - val_acc: 0.7585\n","Epoch 55/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.2215 - acc: 0.9089 - val_loss: 0.2249 - val_acc: 0.9102\n","Epoch 56/100\n","33/33 [==============================] - 13s 398ms/step - loss: 0.1985 - acc: 0.9277 - val_loss: 0.2403 - val_acc: 0.9068\n","Epoch 57/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.1679 - acc: 0.9400 - val_loss: 0.2092 - val_acc: 0.9364\n","Epoch 58/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.1521 - acc: 0.9443 - val_loss: 0.0858 - val_acc: 0.9703\n","Epoch 59/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1370 - acc: 0.9438 - val_loss: 0.3157 - val_acc: 0.8856\n","Epoch 60/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.2228 - acc: 0.9239 - val_loss: 0.0969 - val_acc: 0.9703\n","Epoch 61/100\n","33/33 [==============================] - 13s 408ms/step - loss: 0.1491 - acc: 0.9446 - val_loss: 0.1222 - val_acc: 0.9576\n","Epoch 62/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.1763 - acc: 0.9317 - val_loss: 0.3262 - val_acc: 0.8983\n","Epoch 63/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.1729 - acc: 0.9371 - val_loss: 0.9829 - val_acc: 0.7797\n","Epoch 64/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1380 - acc: 0.9443 - val_loss: 0.2018 - val_acc: 0.9219\n","Epoch 65/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.1568 - acc: 0.9349 - val_loss: 0.3244 - val_acc: 0.8856\n","Epoch 66/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1646 - acc: 0.9368 - val_loss: 0.1203 - val_acc: 0.9492\n","Epoch 67/100\n","33/33 [==============================] - 14s 410ms/step - loss: 0.1658 - acc: 0.9381 - val_loss: 0.1798 - val_acc: 0.9407\n","Epoch 68/100\n","33/33 [==============================] - 13s 399ms/step - loss: 0.1428 - acc: 0.9493 - val_loss: 0.0905 - val_acc: 0.9619\n","Epoch 69/100\n","33/33 [==============================] - 14s 411ms/step - loss: 0.1714 - acc: 0.9403 - val_loss: 0.5850 - val_acc: 0.8263\n","Epoch 70/100\n","33/33 [==============================] - 13s 397ms/step - loss: 0.1316 - acc: 0.9548 - val_loss: 0.2358 - val_acc: 0.9280\n","Epoch 71/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.1701 - acc: 0.9453 - val_loss: 0.1051 - val_acc: 0.9661\n","Epoch 72/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1376 - acc: 0.9513 - val_loss: 0.1676 - val_acc: 0.9322\n","Epoch 73/100\n","33/33 [==============================] - 14s 414ms/step - loss: 0.1267 - acc: 0.9561 - val_loss: 0.2529 - val_acc: 0.9180\n","Epoch 74/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1252 - acc: 0.9580 - val_loss: 0.2788 - val_acc: 0.9364\n","Epoch 75/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.1727 - acc: 0.9345 - val_loss: 0.1413 - val_acc: 0.9534\n","Epoch 76/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1362 - acc: 0.9475 - val_loss: 0.1300 - val_acc: 0.9449\n","Epoch 77/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.1120 - acc: 0.9564 - val_loss: 0.3968 - val_acc: 0.8686\n","Epoch 78/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.0966 - acc: 0.9627 - val_loss: 0.2587 - val_acc: 0.9153\n","Epoch 79/100\n","33/33 [==============================] - 13s 409ms/step - loss: 0.1689 - acc: 0.9389 - val_loss: 0.1278 - val_acc: 0.9492\n","Epoch 80/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.1360 - acc: 0.9526 - val_loss: 0.2418 - val_acc: 0.9195\n","Epoch 81/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1594 - acc: 0.9494 - val_loss: 0.6190 - val_acc: 0.8263\n","Epoch 82/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.1469 - acc: 0.9455 - val_loss: 0.2786 - val_acc: 0.9023\n","Epoch 83/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1652 - acc: 0.9390 - val_loss: 0.3668 - val_acc: 0.8771\n","Epoch 84/100\n","33/33 [==============================] - 13s 403ms/step - loss: 0.1201 - acc: 0.9494 - val_loss: 0.1439 - val_acc: 0.9449\n","Epoch 85/100\n","33/33 [==============================] - 14s 414ms/step - loss: 0.1178 - acc: 0.9570 - val_loss: 0.1018 - val_acc: 0.9534\n","Epoch 86/100\n","33/33 [==============================] - 13s 400ms/step - loss: 0.1069 - acc: 0.9583 - val_loss: 0.2043 - val_acc: 0.9449\n","Epoch 87/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.1346 - acc: 0.9574 - val_loss: 0.3006 - val_acc: 0.8856\n","Epoch 88/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1235 - acc: 0.9542 - val_loss: 0.1416 - val_acc: 0.9576\n","Epoch 89/100\n","33/33 [==============================] - 13s 404ms/step - loss: 0.0913 - acc: 0.9659 - val_loss: 0.2704 - val_acc: 0.9110\n","Epoch 90/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.1454 - acc: 0.9481 - val_loss: 0.2607 - val_acc: 0.9068\n","Epoch 91/100\n","33/33 [==============================] - 14s 413ms/step - loss: 0.1429 - acc: 0.9513 - val_loss: 0.1443 - val_acc: 0.9531\n","Epoch 92/100\n","33/33 [==============================] - 14s 431ms/step - loss: 0.1189 - acc: 0.9614 - val_loss: 0.3477 - val_acc: 0.8983\n","Epoch 93/100\n","33/33 [==============================] - 14s 434ms/step - loss: 0.1585 - acc: 0.9409 - val_loss: 0.1384 - val_acc: 0.9534\n","Epoch 94/100\n","33/33 [==============================] - 13s 407ms/step - loss: 0.1291 - acc: 0.9479 - val_loss: 0.1072 - val_acc: 0.9576\n","Epoch 95/100\n","33/33 [==============================] - 13s 404ms/step - loss: 0.0918 - acc: 0.9665 - val_loss: 0.0968 - val_acc: 0.9576\n","Epoch 96/100\n","33/33 [==============================] - 14s 414ms/step - loss: 0.1483 - acc: 0.9544 - val_loss: 0.5280 - val_acc: 0.8559\n","Epoch 97/100\n","33/33 [==============================] - 13s 409ms/step - loss: 0.1407 - acc: 0.9430 - val_loss: 0.2634 - val_acc: 0.9110\n","Epoch 98/100\n","33/33 [==============================] - 13s 401ms/step - loss: 0.0862 - acc: 0.9686 - val_loss: 0.2761 - val_acc: 0.9280\n","Epoch 99/100\n","33/33 [==============================] - 13s 408ms/step - loss: 0.1268 - acc: 0.9564 - val_loss: 0.3202 - val_acc: 0.9068\n","Epoch 100/100\n","33/33 [==============================] - 13s 402ms/step - loss: 0.1288 - acc: 0.9523 - val_loss: 0.1354 - val_acc: 0.9492\n"],"name":"stdout"}]}]}